# RAG Architecture æ”¹è¿›åˆ†ææŠ¥å‘Š

**æ—¥æœŸ**: 2026-01-09  
**å¯¹æ¯”æ–‡æ¡£**:
- ğŸ“˜ [æˆ‘ä»¬çš„ RAG Embedding Architecture](./RAG_EMBEDDING_ARCHITECTURE.md)
- ğŸ“— [Anthropic Contextual Retrieval Guide](./Enhancing%20RAG%20with%20contextual%20retrieval_Anthropic.md)

---

## ğŸ“Š æ¶æ„å¯¹æ¯”åˆ†æ

### ä¸€è‡´æ€§ï¼ˆæˆ‘ä»¬å·²ç»åšå¯¹çš„ï¼‰

| æŠ€æœ¯ç‚¹ | æˆ‘ä»¬çš„è®¾è®¡ | Anthropic å»ºè®® | åŒ¹é…åº¦ |
|-------|----------|---------------|-------|
| **Contextual Embeddings** | âœ… å®ç°äº† `ContextualRetrievalService` | âœ… æ ¸å¿ƒæŠ€æœ¯ | ğŸ’¯ å®Œå…¨ä¸€è‡´ |
| **Prompt Caching** | âœ… æ–‡æ¡£ä¸­æåˆ°ä½¿ç”¨ Claude Prompt Caching | âœ… é™ä½ 90% æˆæœ¬ | ğŸ’¯ å®Œå…¨ä¸€è‡´ |
| **Hybrid Search** | âœ… è®¾è®¡äº† `HybridRetrievalService` | âœ… Vector + BM25 | ğŸ’¯ å®Œå…¨ä¸€è‡´ |
| **Reranking** | âœ… æ–‡æ¡£ä¸­æåˆ°ä½¿ç”¨ Cohere | âœ… å¯é€‰çš„æœ€åä¼˜åŒ–å±‚ | ğŸ’¯ å®Œå…¨ä¸€è‡´ |
| **è¯­ä¹‰ Chunking** | âœ… `SemanticChunkingService` + AI è¿è´¯æ€§åˆ¤æ–­ | âœ… æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯ | ğŸ’¯ å®Œå…¨ä¸€è‡´ |

### å·®å¼‚ç‚¹ä¸æ”¹è¿›æœºä¼š

#### 1. âš ï¸ **Contextual Embeddings å®ç°ç»†èŠ‚ä¸å¤Ÿå®Œå–„**

**Anthropic çš„åšæ³•**:
```python
def situate_context(doc: str, chunk: str) -> str:
    response = client.messages.create(
        model="claude-haiku",
        messages=[{
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"<document>{doc}</document>",
                    "cache_control": {"type": "ephemeral"}  # ç¼“å­˜æ•´ä¸ªæ–‡æ¡£
                },
                {
                    "type": "text",
                    "text": f"<chunk>{chunk}</chunk>\n\nè¯·ç»™å‡ºç®€æ´çš„ä¸Šä¸‹æ–‡è¯´æ˜"
                }
            ]
        }]
    )
    return response.content[0].text
```

**æˆ‘ä»¬çš„ç°çŠ¶**:
```typescript
// âœ… æœ‰ buildContextPrefix() æ–¹æ³•ï¼Œä½†ä¸»è¦æ˜¯å…ƒæ•°æ®æ‹¼æ¥
private buildContextPrefix(event, signals, chunk): string {
  // ã€Event: ...ã€‘ã€æ—¶é—´: ...ã€‘ã€æ ‡ç­¾: ...ã€‘
  return parts.join(' ');
}

// âŒ ç¼ºå°‘ï¼šç”¨ LLM ç”Ÿæˆ chunk åœ¨æ•´ä¸ª Event ä¸­çš„ä¸Šä¸‹æ–‡è¯´æ˜
```

**é—®é¢˜**: æˆ‘ä»¬çš„ä¸Šä¸‹æ–‡å¢å¼ºæ˜¯"å…ƒæ•°æ®æ³¨å…¥"ï¼Œè€Œä¸æ˜¯"è¯­ä¹‰è¯´æ˜ç”Ÿæˆ"

**æ”¹è¿›æ–¹æ¡ˆ**: æ·»åŠ  `generateChunkContext()` æ–¹æ³•

---

#### 2. âš ï¸ **BM25 å®ç°ç¼ºå°‘ Contextual BM25**

**Anthropic çš„åšæ³•**:
```python
# BM25 ç´¢å¼•æ—¶ï¼ŒåŒæ—¶ç´¢å¼• original content å’Œ contextualized content
index_settings = {
    "mappings": {
        "properties": {
            "content": {"type": "text"},                      # åŸå§‹å†…å®¹
            "contextualized_content": {"type": "text"}        # ä¸Šä¸‹æ–‡å¢å¼ºå†…å®¹
        }
    }
}

# æœç´¢æ—¶ï¼ŒåŒæ—¶åœ¨ä¸¤ä¸ªå­—æ®µä¸­åŒ¹é…
query = {
    "multi_match": {
        "query": query_text,
        "fields": ["content", "contextualized_content"]  # åŒå­—æ®µæ£€ç´¢
    }
}
```

**æˆ‘ä»¬çš„ç°çŠ¶**:
```typescript
// âŒ HybridRetrievalService æ–‡æ¡£ä¸­æ²¡æœ‰æåˆ° BM25 ç´¢å¼•è®¾è®¡
// âŒ æ²¡æœ‰æ˜ç¡®è¯´æ˜ BM25 æ˜¯å¦ä½¿ç”¨ contextualized text
```

**æ”¹è¿›æ–¹æ¡ˆ**: åœ¨ BM25 ç´¢å¼•ä¸­æ·»åŠ  `contextualizedText` å­—æ®µ

---

#### 3. âš ï¸ **Prompt Caching æˆæœ¬è®¡ç®—ä¸å¤Ÿè¯¦ç»†**

**Anthropic çš„æ•°æ®**:
- **é¦–ä¸ª chunk**: å†™å…¥ç¼“å­˜ï¼ˆæ”¯ä»˜ 1.25x æˆæœ¬ï¼‰
- **åç»­ chunks**: ä»ç¼“å­˜è¯»å–ï¼ˆ90% æŠ˜æ‰£ï¼‰
- **å®é™…æˆæœ¬**: å¯¹äº 800-token chunks + 8k-token documentï¼Œæ€»æˆæœ¬ $1.02 per million document tokens

**æˆ‘ä»¬çš„ç°çŠ¶**:
```typescript
// âœ… æåˆ°äº† Prompt Caching
// âŒ ä½†æ²¡æœ‰ç»™å‡ºè¯¦ç»†çš„æˆæœ¬è®¡ç®—å…¬å¼å’Œæ¡ˆä¾‹
```

**æ”¹è¿›æ–¹æ¡ˆ**: æ·»åŠ è¯¦ç»†çš„æˆæœ¬è®¡ç®—ç¤ºä¾‹

---

#### 4. âš ï¸ **Reranking ç­–ç•¥ä¸å¤Ÿæ¸…æ™°**

**Anthropic çš„ç­–ç•¥**:
1. **Over-retrieve**: æ£€ç´¢ 10x æ•°é‡ï¼ˆä¾‹å¦‚éœ€è¦ 10 ä¸ªç»“æœï¼Œå…ˆæ£€ç´¢ 100 ä¸ªï¼‰
2. **Rerank**: ä½¿ç”¨ Cohere `rerank-english-v3.0` é‡æ–°æ’åº
3. **Select top-k**: è¿”å›æœ€ç»ˆçš„ k ä¸ªç»“æœ

**æ€§èƒ½æ•°æ®**:
- Pass@10: 92.34% (contextual embeddings alone) â†’ 95.26% (+ reranking)
- é¢å¤–æˆæœ¬: ~$0.002 per query
- é¢å¤–å»¶è¿Ÿ: 100-200ms

**æˆ‘ä»¬çš„ç°çŠ¶**:
```typescript
// âœ… æåˆ°äº† Reranking
// âŒ ä½†æ²¡æœ‰è¯´æ˜ over-retrieve çš„å€æ•°ï¼ˆ10xï¼‰
// âŒ æ²¡æœ‰ç»™å‡ºæ€§èƒ½æå‡æ•°æ®
```

**æ”¹è¿›æ–¹æ¡ˆ**: è¡¥å…… over-retrieve ç­–ç•¥å’Œæ€§èƒ½æ•°æ®

---

#### 5. âš ï¸ **è¯„ä¼°æŒ‡æ ‡ç¼ºå¤± Pass@k**

**Anthropic ä½¿ç”¨çš„è¯„ä¼°æŒ‡æ ‡**:
- **Pass@k**: æ£€æŸ¥ golden chunk æ˜¯å¦åœ¨å‰ k ä¸ªç»“æœä¸­
- **Baseline**: Pass@10 = 87.15%
- **+ Contextual Embeddings**: Pass@10 = 92.34%
- **+ Hybrid Search**: Pass@10 = 93.21%
- **+ Reranking**: Pass@10 = 95.26%

**æˆ‘ä»¬çš„ç°çŠ¶**:
```typescript
// âŒ æ–‡æ¡£ä¸­æ²¡æœ‰æåˆ° Pass@k è¯„ä¼°æŒ‡æ ‡
// âŒ æ²¡æœ‰ç»™å‡ºå„ä¸ªä¼˜åŒ–æ­¥éª¤çš„æ€§èƒ½æå‡æ•°æ®
```

**æ”¹è¿›æ–¹æ¡ˆ**: æ·»åŠ  Pass@k è¯„ä¼°æ¡†æ¶

---

## ğŸ¯ æ ¸å¿ƒæ”¹è¿›å»ºè®®

### ä¼˜å…ˆçº§ P0ï¼ˆå¿…é¡»å®ç°ï¼‰

#### 1. å¢å¼º Contextual Embeddings å®ç°

**ç°çŠ¶**: æˆ‘ä»¬çš„ `ContextualRetrievalService.buildContextPrefix()` åªæ˜¯ç®€å•æ‹¼æ¥å…ƒæ•°æ®

**ç›®æ ‡**: æ”¹ä¸ºç”¨ LLM ç”Ÿæˆ chunk åœ¨æ•´ä¸ª Event ä¸­çš„è¯­ä¹‰ä¸Šä¸‹æ–‡

**å®ç°**:

```typescript
class ContextualRetrievalService {
  /**
   * ä¸º chunk ç”Ÿæˆä¸Šä¸‹æ–‡è¯´æ˜ï¼ˆç”¨ Claudeï¼‰
   * 
   * å‚è€ƒ: Anthropic Contextual Retrieval Guide
   */
  async generateChunkContext(
    event: Event,
    chunk: RAGChunk,
  ): Promise<string> {
    // 1. è·å–å®Œæ•´ Event å†…å®¹ï¼ˆä½œä¸º documentï¼‰
    const fullEventText = this.eventToFullText(event);
    
    // 2. ä½¿ç”¨ Claude ç”Ÿæˆä¸Šä¸‹æ–‡
    const response = await this.anthropicClient.messages.create({
      model: 'claude-3-haiku-20240307',
      max_tokens: 100,
      temperature: 0,
      messages: [{
        role: 'user',
        content: [
          {
            type: 'text',
            text: `<document>${fullEventText}</document>`,
            cache_control: { type: 'ephemeral' },  // ç¼“å­˜æ•´ä¸ªæ–‡æ¡£
          },
          {
            type: 'text',
            text: `<chunk>${chunk.text}</chunk>

è¯·ç”¨ä¸€å¥è¯ï¼ˆ20-50å­—ï¼‰è¯´æ˜è¿™ä¸ª chunk åœ¨æ•´ä¸ª Event ä¸­çš„ä½ç½®å’Œä½œç”¨ã€‚
åªè¿”å›è¯´æ˜ï¼Œä¸è¦è§£é‡Šã€‚`,
          },
        ],
      }],
      extra_headers: { 'anthropic-beta': 'prompt-caching-2024-07-31' },
    });
    
    return response.content[0].text;
  }
  
  /**
   * æœ€ç»ˆçš„ä¸Šä¸‹æ–‡å¢å¼ºï¼ˆå…ƒæ•°æ® + LLM è¯´æ˜ï¼‰
   */
  async enhanceChunk(chunk: RAGChunk): Promise<string> {
    const event = await this.storageManager.getEvent(chunk.metadata.eventId!);
    if (!event) return chunk.text;
    
    // A. å…ƒæ•°æ®å‰ç¼€ï¼ˆå¿«é€Ÿæ ‡è¯†ï¼‰
    const metadataPrefix = this.buildContextPrefix(event, [], chunk);
    
    // B. LLM ç”Ÿæˆçš„è¯­ä¹‰è¯´æ˜ï¼ˆæ·±åº¦ç†è§£ï¼‰
    const semanticContext = await this.generateChunkContext(event, chunk);
    
    // C. ç»„åˆ
    return `${metadataPrefix}\nã€è¯´æ˜: ${semanticContext}ã€‘\n\n${chunk.text}`;
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const enhanced = await contextualRetrievalService.enhanceChunk(chunk);

// è¾“å‡º:
// ã€Event: æŠ€æœ¯è¯„å®¡ä¼šè®®ã€‘ã€æ—¶é—´: 2025-12-06 14:30ã€‘ã€å‚ä¸è€…: @å¼ ä¸‰ @æå››ã€‘
// ã€è¯´æ˜: è¿™æ®µæ–‡å­—è®¨è®ºäº†æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–çš„ä¸‰ä¸ªå…·ä½“æ–¹æ¡ˆï¼Œæ˜¯ä¼šè®®æ ¸å¿ƒå†³ç­–éƒ¨åˆ†ã€‘
//
// è®¨è®ºäº†æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–æ–¹æ¡ˆ...
```

**æˆæœ¬å½±å“**:
- æ¯ä¸ª chunk å¢åŠ çº¦ 50-100 tokens çš„ LLM ç”Ÿæˆæˆæœ¬
- ä½¿ç”¨ Prompt Caching åï¼Œ**åç»­ chunks æˆæœ¬é™ä½ 90%**
- å¯¹äº 10K ç”¨æˆ·ï¼Œé¢„è®¡å¢åŠ æˆæœ¬ ~$5/æœˆï¼ˆç›¸æ¯”æ£€ç´¢è´¨é‡æå‡ï¼Œæ€§ä»·æ¯”æé«˜ï¼‰

---

#### 2. å®ç° Contextual BM25

**ç°çŠ¶**: æ–‡æ¡£ä¸­æåˆ° `HybridRetrievalService`ï¼Œä½†æ²¡æœ‰æ˜ç¡® BM25 ç´¢å¼•è®¾è®¡

**ç›®æ ‡**: BM25 ç´¢å¼•åŒæ—¶åŒ…å« original content å’Œ contextualized content

**å®ç°**:

```typescript
/**
 * ElasticsearchBM25 æœåŠ¡ï¼ˆæ”¯æŒ Contextual BM25ï¼‰
 */
class ElasticsearchBM25Service {
  async createIndex(): Promise<void> {
    await this.client.indices.create({
      index: 'rag_chunks',
      settings: {
        analysis: {
          analyzer: {
            default: { type: 'english' },
            chinese: { type: 'icu_analyzer' },  // æ”¯æŒä¸­æ–‡
          },
        },
        similarity: {
          default: { type: 'BM25' },
        },
      },
      mappings: {
        properties: {
          // åŸå§‹å†…å®¹ï¼ˆç”¨æˆ·ç¼–å†™çš„ï¼‰
          content: {
            type: 'text',
            analyzer: 'chinese',
          },
          
          // ä¸Šä¸‹æ–‡å¢å¼ºå†…å®¹ï¼ˆLLM ç”Ÿæˆçš„ï¼‰
          contextualizedContent: {
            type: 'text',
            analyzer: 'chinese',
          },
          
          // å…ƒæ•°æ®ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
          eventId: { type: 'keyword' },
          tags: { type: 'keyword' },
          createdAt: { type: 'date' },
        },
      },
    });
  }
  
  /**
   * ç´¢å¼• chunkï¼ˆåŒ…å« contextualized contentï¼‰
   */
  async indexChunk(
    chunkId: string,
    originalText: string,
    contextualizedText: string,
    metadata: ChunkMetadata,
  ): Promise<void> {
    await this.client.index({
      index: 'rag_chunks',
      id: chunkId,
      document: {
        content: originalText,
        contextualizedContent: contextualizedText,  // â­ å…³é”®
        eventId: metadata.eventId,
        tags: metadata.tags,
        createdAt: metadata.createdAt,
      },
    });
  }
  
  /**
   * æœç´¢ï¼ˆåœ¨ä¸¤ä¸ªå­—æ®µä¸­åŒæ—¶åŒ¹é…ï¼‰
   */
  async search(query: string, k: number): Promise<SearchResult[]> {
    const response = await this.client.search({
      index: 'rag_chunks',
      query: {
        multi_match: {
          query,
          fields: [
            'content^1.5',                // åŸå§‹å†…å®¹æƒé‡ 1.5
            'contextualizedContent^1.0',  // ä¸Šä¸‹æ–‡å†…å®¹æƒé‡ 1.0
          ],
        },
      },
      size: k,
    });
    
    return response.hits.hits.map(hit => ({
      chunkId: hit._id,
      score: hit._score,
      content: hit._source.content,
    }));
  }
}
```

**æ€§èƒ½æå‡**:
- Anthropic æ•°æ®: Contextual BM25 å°† Pass@10 ä» 92.34% æå‡è‡³ 93.21%
- é¢„è®¡æˆ‘ä»¬çš„ç³»ç»Ÿå¯è·å¾—ç±»ä¼¼æå‡ï¼ˆ~1% æå‡ï¼‰

---

#### 3. æ·»åŠ  Pass@k è¯„ä¼°æ¡†æ¶

**ç°çŠ¶**: æ²¡æœ‰æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡

**ç›®æ ‡**: å®ç° Pass@k è¯„ä¼°ï¼Œè¿½è¸ªæ¯æ¬¡ä¼˜åŒ–çš„æ€§èƒ½æå‡

**å®ç°**:

```typescript
/**
 * Pass@k è¯„ä¼°å™¨
 * 
 * Pass@k: æ£€æŸ¥ golden chunk æ˜¯å¦åœ¨å‰ k ä¸ªæ£€ç´¢ç»“æœä¸­
 */
class PassAtKEvaluator {
  /**
   * è¿è¡Œè¯„ä¼°
   * 
   * @param queries è¯„ä¼°æ•°æ®é›†ï¼ˆæ¯ä¸ª query åŒ…å« golden chunkï¼‰
   * @param retrievalFn æ£€ç´¢å‡½æ•°
   * @param kValues Pass@k çš„ k å€¼åˆ—è¡¨ï¼ˆé»˜è®¤ [5, 10, 20]ï¼‰
   */
  async evaluate(
    queries: EvaluationQuery[],
    retrievalFn: (query: string, k: number) => Promise<SearchResult[]>,
    kValues: number[] = [5, 10, 20],
  ): Promise<EvaluationReport> {
    const results: Record<number, number> = {};
    
    for (const k of kValues) {
      let successCount = 0;
      
      for (const query of queries) {
        const retrieved = await retrievalFn(query.query, k);
        const goldenChunkIds = query.goldenChunkIds;
        
        // æ£€æŸ¥ golden chunk æ˜¯å¦åœ¨å‰ k ä¸ªç»“æœä¸­
        const found = retrieved
          .slice(0, k)
          .some(result => goldenChunkIds.includes(result.chunkId));
        
        if (found) successCount++;
      }
      
      results[k] = (successCount / queries.length) * 100;
    }
    
    return {
      totalQueries: queries.length,
      passAtK: results,
    };
  }
  
  /**
   * å¯¹æ¯”ä¸¤ä¸ªæ£€ç´¢ç­–ç•¥
   */
  async compare(
    queries: EvaluationQuery[],
    baselineFn: RetrievalFn,
    improvedFn: RetrievalFn,
    kValues: number[] = [5, 10, 20],
  ): Promise<ComparisonReport> {
    const baselineResults = await this.evaluate(queries, baselineFn, kValues);
    const improvedResults = await this.evaluate(queries, improvedFn, kValues);
    
    const improvements: Record<number, number> = {};
    for (const k of kValues) {
      improvements[k] = improvedResults.passAtK[k] - baselineResults.passAtK[k];
    }
    
    return {
      baseline: baselineResults,
      improved: improvedResults,
      improvements,
    };
  }
}

// ä½¿ç”¨ç¤ºä¾‹
interface EvaluationQuery {
  query: string;
  goldenChunkIds: string[];  // æ­£ç¡®ç­”æ¡ˆï¼ˆå¯èƒ½æœ‰å¤šä¸ªï¼‰
}

// 1. å‡†å¤‡è¯„ä¼°æ•°æ®é›†
const testQueries: EvaluationQuery[] = [
  {
    query: 'ä»£ç ç­¾åçš„è§£å†³æ–¹æ¡ˆ',
    goldenChunkIds: ['chunk_abc123'],
  },
  {
    query: '@å¼ ä¸‰ å‚ä¸çš„æ•°æ®åº“ä¼˜åŒ–è®¨è®º',
    goldenChunkIds: ['chunk_def456', 'chunk_ghi789'],
  },
  // ... æ›´å¤šæµ‹è¯• queries
];

// 2. è¯„ä¼° Baselineï¼ˆæ—  Contextual Embeddingsï¼‰
const evaluator = new PassAtKEvaluator();
const baselineReport = await evaluator.evaluate(
  testQueries,
  (query, k) => baselineRetrievalService.search(query, k),
);

console.log('Baseline Pass@10:', baselineReport.passAtK[10]);
// é¢„æœŸ: ~85-88%

// 3. è¯„ä¼°æ”¹è¿›ç‰ˆï¼ˆ+ Contextual Embeddingsï¼‰
const improvedReport = await evaluator.evaluate(
  testQueries,
  (query, k) => contextualRetrievalService.search(query, k),
);

console.log('Improved Pass@10:', improvedReport.passAtK[10]);
// ç›®æ ‡: ~92-95%

// 4. å¯¹æ¯”æŠ¥å‘Š
const comparison = await evaluator.compare(
  testQueries,
  baselineFn,
  improvedFn,
);

console.log('Improvement:', comparison.improvements);
// è¾“å‡º: { 5: +7.2%, 10: +5.8%, 20: +3.4% }
```

**è¾“å‡ºç¤ºä¾‹**:

```
====================================
Pass@k Evaluation Report
====================================
Strategy: Contextual Embeddings + Hybrid Search

Pass@5:  88.12% âœ… (+7.2% vs Baseline)
Pass@10: 92.34% âœ… (+5.8% vs Baseline)
Pass@20: 94.29% âœ… (+3.4% vs Baseline)

Total Queries: 248
====================================
```

---

### ä¼˜å…ˆçº§ P1ï¼ˆå»ºè®®å®ç°ï¼‰

#### 4. ä¼˜åŒ– Reranking ç­–ç•¥

**æ”¹è¿›ç‚¹**:
1. **æ˜ç¡® Over-retrieve å€æ•°**: æ£€ç´¢ 10x æ•°é‡ï¼ˆéœ€è¦ 10 ä¸ªç»“æœï¼Œå…ˆæ£€ç´¢ 100 ä¸ªï¼‰
2. **æ·»åŠ æ€§èƒ½æ•°æ®**: Reranking æå‡ Pass@10 çº¦ 2-3%
3. **æˆæœ¬-æ€§èƒ½æƒè¡¡è¡¨**:

```typescript
/**
 * Reranking é…ç½®ï¼ˆæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰
 */
interface RerankConfig {
  enabled: boolean;
  overRetrieveMultiplier: number;  // é»˜è®¤ 10x
  model: 'cohere-rerank-english-v3.0' | 'cohere-rerank-multilingual-v3.0';
  costPerQuery: number;  // $0.002
  latencyMs: number;     // 100-200ms
}

const rerankConfig: RerankConfig = {
  enabled: true,
  overRetrieveMultiplier: 10,
  model: 'cohere-rerank-multilingual-v3.0',  // æ”¯æŒä¸­æ–‡
  costPerQuery: 0.002,
  latencyMs: 150,
};

class HybridRetrievalService {
  async search(
    query: string,
    k: number,
    config: RerankConfig,
  ): Promise<SearchResult[]> {
    // 1. Over-retrieve (10x)
    const candidateCount = k * config.overRetrieveMultiplier;
    
    // 2. Vector + BM25 hybrid search
    const candidates = await this.hybridSearch(query, candidateCount);
    
    // 3. Rerank (å¯é€‰)
    if (config.enabled) {
      return await this.rerank(query, candidates, k, config.model);
    }
    
    return candidates.slice(0, k);
  }
  
  private async rerank(
    query: string,
    candidates: SearchResult[],
    topK: number,
    model: string,
  ): Promise<SearchResult[]> {
    const response = await this.cohereClient.rerank({
      model,
      query,
      documents: candidates.map(c => c.content),
      top_n: topK,
    });
    
    return response.results.map(r => ({
      ...candidates[r.index],
      rerankScore: r.relevance_score,
    }));
  }
}
```

---

#### 5. è¡¥å…… Prompt Caching æˆæœ¬è®¡ç®—

**æ·»åŠ åˆ°æ–‡æ¡£çš„"æˆæœ¬ä¸æ€§èƒ½ä¼˜åŒ–"ç« èŠ‚**:

```markdown
### Prompt Caching è¯¦ç»†æˆæœ¬åˆ†æ

**åœºæ™¯**: ä¸º 10K ç”¨æˆ·çš„ 3M semantic chunks ç”Ÿæˆ contextualized embeddings

**å‚æ•°**:
- Chunk å¹³å‡é•¿åº¦: 800 tokens
- Event å¹³å‡é•¿åº¦: 8,000 tokens
- æ¯ä¸ª Event åŒ…å« ~20 chunks

**æˆæœ¬è®¡ç®—**:

| é¡¹ç›® | Token æ•°é‡ | å•ä»· | æˆæœ¬ |
|-----|-----------|------|-----|
| **é¦–ä¸ª chunkï¼ˆå†™ç¼“å­˜ï¼‰** | 8,000 tokens | $0.30 / 1M Ã— 1.25 | $0.003 |
| **åç»­ 19 chunksï¼ˆè¯»ç¼“å­˜ï¼‰** | 8,000 Ã— 19 = 152,000 tokens | $0.30 / 1M Ã— 0.1 | $0.00456 |
| **ç”Ÿæˆçš„ä¸Šä¸‹æ–‡** | 50 Ã— 20 = 1,000 tokens | $1.25 / 1M | $0.00125 |
| **æ€»æˆæœ¬ï¼ˆæ¯ä¸ª Eventï¼‰** | - | - | $0.00881 |

**æ€»æˆæœ¬ï¼ˆ10K ç”¨æˆ·ï¼‰**:
- Event æ•°é‡: 10K users Ã— 100 events = 1M events
- æ€»æˆæœ¬: $0.00881 Ã— 1M = **$8,810/æ¬¡**ï¼ˆä¸€æ¬¡æ€§ï¼‰

**å¯¹æ¯”æ— ç¼“å­˜**:
- æ— ç¼“å­˜æˆæœ¬: 8,000 tokens Ã— 20 chunks Ã— 1M events Ã— $0.30 / 1M = **$48,000**
- **èŠ‚çœ**: $48,000 - $8,810 = **$39,190 (82% èŠ‚çœ)**

**ç»“è®º**: Prompt Caching å°† Contextual Embeddings æˆæœ¬ä»ä¸å¯æ‰¿å—ï¼ˆ$48Kï¼‰é™è‡³å¯æ¥å—ï¼ˆ$8.8Kï¼‰
```

---

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡è·¯å¾„

åŸºäº Anthropic çš„æ•°æ®ï¼Œæˆ‘ä»¬é¢„æœŸçš„ä¼˜åŒ–è·¯å¾„ï¼š

```
Baseline RAG (TimeNode-Level chunks)
  Pass@10: ~85%
  â†“
+ Semantic Chunking (AI-driven aggregation)
  Pass@10: ~87% (+2%)
  â†“
+ Contextual Embeddings (LLM-generated context)
  Pass@10: ~92% (+5%)  â­ æœ€å¤§æå‡
  â†“
+ Contextual BM25 (dual-field search)
  Pass@10: ~93% (+1%)
  â†“
+ Reranking (Cohere, 10x over-retrieve)
  Pass@10: ~95% (+2%)
```

**æ€»æå‡**: 85% â†’ 95% (ç»å¯¹æå‡ 10%, ç›¸å¯¹æå‡ 11.8%)

---

## ğŸ› ï¸ å®æ–½è®¡åˆ’

### Phase 1: æ ¸å¿ƒä¼˜åŒ–ï¼ˆ2 å‘¨ï¼‰

**Week 1: Contextual Embeddings å¢å¼º**
- [ ] å®ç° `generateChunkContext()` æ–¹æ³•ï¼ˆç”¨ Claudeï¼‰
- [ ] æ·»åŠ  Prompt Caching æ”¯æŒ
- [ ] æµ‹è¯•æˆæœ¬ï¼šé¢„æœŸ <$10ï¼ˆå¤„ç†æµ‹è¯•æ•°æ®é›†ï¼‰

**Week 2: Contextual BM25 + è¯„ä¼°æ¡†æ¶**
- [ ] å®ç° `ElasticsearchBM25Service`ï¼ˆæ”¯æŒ dual-field searchï¼‰
- [ ] å®ç° `PassAtKEvaluator`
- [ ] è¿è¡Œ Baseline è¯„ä¼°ï¼Œå»ºç«‹æ€§èƒ½åŸºå‡†

### Phase 2: é«˜çº§ä¼˜åŒ–ï¼ˆ1 å‘¨ï¼‰

**Week 3: Reranking + æ€§èƒ½è°ƒä¼˜**
- [ ] é›†æˆ Cohere Rerank API
- [ ] å®ç° over-retrieve ç­–ç•¥ï¼ˆ10xï¼‰
- [ ] è¿è¡Œå®Œæ•´è¯„ä¼°ï¼Œå¯¹æ¯”æ‰€æœ‰ç­–ç•¥

### Phase 3: ç”Ÿäº§éƒ¨ç½²ï¼ˆ1 å‘¨ï¼‰

**Week 4: ä¼˜åŒ–ä¸ç›‘æ§**
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§ï¼ˆæ£€ç´¢å»¶è¿Ÿã€æˆæœ¬è¿½è¸ªï¼‰
- [ ] A/B æµ‹è¯•ï¼ˆ10% ç”¨æˆ·ä½¿ç”¨æ–°ç­–ç•¥ï¼‰
- [ ] æ–‡æ¡£æ›´æ–°

---

## ğŸ’¡ é¢å¤–å‘ç°

### 1. Anthropic ä½¿ç”¨çš„è¯„ä¼°æ•°æ®é›†è®¾è®¡

**ç»“æ„**:
```json
{
  "query": "ç”¨æˆ·çš„æœç´¢é—®é¢˜",
  "golden_chunk_uuids": [["doc_uuid", chunk_index]],
  "golden_documents": [
    {
      "uuid": "doc_123",
      "content": "å®Œæ•´æ–‡æ¡£å†…å®¹",
      "chunks": [
        {
          "index": 0,
          "content": "chunk å†…å®¹"
        }
      ]
    }
  ]
}
```

**æˆ‘ä»¬å¯ä»¥å€Ÿé‰´**:
- æ„å»ºç±»ä¼¼çš„æµ‹è¯•æ•°æ®é›†ï¼ˆ100-200 queriesï¼‰
- æ¯ä¸ª query å…³è” 1-2 ä¸ª golden chunks
- ç”¨äºæŒç»­è¯„ä¼°å„ä¸ªä¼˜åŒ–æ­¥éª¤

### 2. å‘é‡æ•°æ®åº“é€‰å‹

**Anthropic ä½¿ç”¨**: è‡ªç ” `VectorDB` classï¼ˆç®€å• in-memory + pickleï¼‰

**æˆ‘ä»¬çš„é€‰æ‹©**:
- å¼€å‘é˜¶æ®µ: å¯ç”¨ in-memoryï¼ˆå¿«é€Ÿè¿­ä»£ï¼‰
- ç”Ÿäº§ç¯å¢ƒ: å»ºè®® Milvus æˆ– Qdrantï¼ˆæ”¯æŒåˆ†å¸ƒå¼ï¼‰

### 3. Embedding æ¨¡å‹é€‰å‹

**Anthropic ä½¿ç”¨**: Voyage AI `voyage-2`

**æˆ‘ä»¬çš„å¤šåœ°åŸŸç­–ç•¥**:
- å›½å†…: é€šä¹‰ `qwen-text-embedding`
- æµ·å¤–: Voyage AI æˆ– OpenAI `text-embedding-3-small`

**å»ºè®®**: è¯„ä¼°æ—¶åŒæ—¶æµ‹è¯•ä¸¤ä¸ªæ¨¡å‹ï¼Œé€‰æ‹© Pass@10 æ›´é«˜çš„

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. **Anthropic Contextual Retrieval Guide** (æœ¬åœ°æ–‡æ¡£)
   - è¯¦ç»†çš„ä»£ç ç¤ºä¾‹å’Œæˆæœ¬è®¡ç®—
   
2. **æˆ‘ä»¬çš„ RAG Embedding Architecture**
   - SSOT-first è®¾è®¡åŸåˆ™
   - å¤šç²’åº¦ Chunking ç­–ç•¥

3. **å¤–éƒ¨èµ„æº**:
   - [Cohere Rerank API](https://docs.cohere.com/reference/rerank)
   - [Elasticsearch BM25](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html)
   - [Voyage AI Embeddings](https://docs.voyageai.com/embeddings/)

---

## âœ… æ£€æŸ¥æ¸…å•

åœ¨å®æ–½æ”¹è¿›å‰ï¼Œç¡®è®¤ä»¥ä¸‹äº‹é¡¹ï¼š

- [ ] å·²é˜…è¯» Anthropic å®Œæ•´æŒ‡å—
- [ ] å·²ç†è§£ Prompt Caching æˆæœ¬æ¨¡å‹
- [ ] å·²å‡†å¤‡è¯„ä¼°æ•°æ®é›†ï¼ˆ100+ queriesï¼‰
- [ ] å·²é…ç½® Claude API Keyï¼ˆæ”¯æŒ Prompt Cachingï¼‰
- [ ] å·²é…ç½® Elasticsearchï¼ˆç”¨äº BM25ï¼‰
- [ ] å·²é…ç½® Cohere API Keyï¼ˆç”¨äº Rerankingï¼‰
- [ ] å·²å»ºç«‹æ€§èƒ½ç›‘æ§ï¼ˆè¿½è¸ª Pass@kï¼‰

---

**ä¸‹ä¸€æ­¥**: å…ˆå®æ–½ Phase 1ï¼ˆContextual Embeddings å¢å¼ºï¼‰ï¼Œè¿è¡Œ Pass@k è¯„ä¼°ï¼ŒéªŒè¯æ€§èƒ½æå‡åå†è¿›è¡Œ Phase 2/3ã€‚
