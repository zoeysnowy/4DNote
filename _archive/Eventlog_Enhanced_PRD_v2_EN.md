# Eventlog Enhanced â€” äº§å“éœ€æ±‚æ–‡æ¡£ v2.0

**äº§å“åç§°ï¼š** 4DNote â€” æ™ºèƒ½è®°å¿†ä¸å™äº‹ç³»ç»Ÿ  
**ç‰ˆæœ¬ï¼š** v2.0ï¼ˆæ•´åˆç‰ˆï¼‰  
**çŠ¶æ€ï¼š** å·²æ‰¹å‡†å¼€å‘  
**æœ€åæ›´æ–°ï¼š** 2025-01-23

---

## 0. æ‰§è¡Œæ‘˜è¦

**äº§å“æ„¿æ™¯**  
å°†ç¢ç‰‡åŒ–çš„æ—¥å¸¸äº¤äº’ï¼ˆæ€è€ƒã€ä¼šè®®ã€AI å¯¹è¯ã€ç½‘é¡µå‰ªè—ï¼‰è½¬åŒ–ä¸ºç»“æ„åŒ–ã€å¯å›é¡¾çš„å™äº‹è®°å¿†ï¼Œç”¨æˆ·æŠ•å…¥æœ€å°‘ç²¾åŠ›ã€‚

**æ ¸å¿ƒä»·å€¼ä¸»å¼ **  
- **å¯¹äºå¿™ç¢Œçš„ä¸“ä¸šäººå£«**ï¼šé€šè¿‡è‡ªåŠ¨ç”Ÿæˆçš„æ—¶é—´éª¨æ¶å™äº‹ï¼Œè·å¾—"ä»Šå¤©æˆ‘åšäº†ä»€ä¹ˆ"çš„å®‰å¿ƒæ„Ÿ
- **å¯¹äºçŸ¥è¯†å·¥ä½œè€…**ï¼šé€šè¿‡æ™ºèƒ½æ”¶è·æ•è·å’ŒåŸºäºè¯æ®çš„å›é¡¾ï¼Œæç‚¼"ä»Šå¤©æˆ‘ç†è§£äº†ä»€ä¹ˆ"
- **å¯¹äº AI æ·±åº¦ç”¨æˆ·**ï¼šé€šè¿‡è‡ªåŠ¨ç»“ç®—æœºåˆ¶ï¼Œå°†é•¿æ—¶é—´ AI åä½œä¼šè¯è½¬åŒ–ä¸ºæ¸…æ™°ã€å¯å¤ç”¨çš„æ”¶è·
- **å¯¹äºä¼šè®®å‚ä¸è€…**ï¼šç”¨æ™ºèƒ½å®šå¸§å¿«ç…§æ•è·è§†è§‰è¯æ®ï¼Œè€Œéä¾µå…¥æ€§çš„å…¨ç¨‹å½•å±
- **å¯¹äºéŸ³é¢‘ç¬”è®°ç”¨æˆ·**ï¼šé€šè¿‡ RECNote é”šç‚¹å°†éŸ³é¢‘ä¸æ–‡å­—ç¬”è®°åŒæ­¥ï¼Œå®ç°è½»æ¾çš„å›æ”¾å¯¼èˆª

**è®¾è®¡å“²å­¦**  
- **åŸºäºæ¥æºçš„ä¿¡å·ä¼˜äºè¯­ä¹‰çŒœæµ‹**ï¼šç”¨æˆ·è¡Œä¸ºï¼ˆé«˜äº®ã€æ‰‹åŠ¨æ ‡è®°ã€ç–‘é—®ï¼‰é©±åŠ¨ä¼˜å…ˆçº§æ’åº
- **å¤åˆ©å¼å›é¡¾**ï¼šæ¯æ—¥ â†’ æ¯å‘¨ â†’ æ¯æœˆå™äº‹é€šè¿‡è¯æ®ç§¯ç´¯ç›¸äº’æ„å»º
- **æœ¬åœ°ä¼˜å…ˆçš„éšç§ä¿æŠ¤**ï¼šéŸ³é¢‘å’Œæˆªå›¾é»˜è®¤å­˜å‚¨åœ¨è®¾å¤‡ä¸Šï¼›äº‘åŒæ­¥å¯é€‰
- **é›¶ç„¦è™‘å½’æ¡£**ï¼šæ‰€æœ‰äº¤äº’è‡ªåŠ¨æ•è·ä¸ºæ½œåœ¨è¯æ®ï¼Œå¯éšæ—¶è¿‡æ»¤/æ£€ç´¢

---

## 1. Product Background & User Problems

### 1.1 Target Users

**Primary Personas**
1. **Knowledge Workers** (researchers, engineers, analysts)
   - Heavy note-takers who struggle with "where did I see that idea?"
   - AI conversation partners generating valuable insights that get lost in chat history
   
2. **Meeting-Heavy Professionals** (managers, consultants)
   - Need meeting minutes but hate manual note-taking
   - Privacy-conscious about full video recording
   
3. **Reflective Learners** (students, self-improvement enthusiasts)
   - Want to review "what resonated with me this week"
   - Struggle to maintain journaling consistency

### 1.2 User Pain Points

**P1: Fragmentation & Loss** (ç¢ç¢å¿µç»´æŠ¤æˆæœ¬é«˜)
- Scattered notes across tools (chat logs, docs, sticky notes)
- No automatic consolidation â†’ manual copy-paste burden
- Important thoughts buried in noise

**P2: Non-retrievable Emotional Context** (æƒ…ç»ª/æŒ£æ‰ä¸å¯æœç´¢)
- "I remember feeling excited about something last Tuesday" â†’ unsearchable
- Key struggles/breakthroughs lost without deliberate journaling

**P3: AI Conversation Sedimentation** (AI å¯¹è¯æ²‰æ·€éš¾)
- Long AI cowork sessions produce value but lack structured outputs
- Insights exist only as chat history, not as reusable knowledge cards

**P4: Meeting Evidence Overload** (ä¼šè®®è¯æ®æˆæœ¬é«˜)
- Full screen recording = storage bloat + privacy concerns
- Manual screenshot timing misses key moments
- Audio-note sync requires manual timestamp tagging

### 1.3 Opportunity Space

**Market Gaps**
- Granola: Great meeting notes but lacks daily narrative continuity
- Reflect/Mem: Good for manual inputs, weak on automatic evidence capture
- Notion/Obsidian: Powerful but require manual organization upfront

**Our Differentiator**: Automatic evidence collection + intelligent review synthesis + privacy-first design

---

## 2. Core Concepts & Terminology

### 2.1 Structural Primitives

**Note** (æ–‡æ¡£)  
Top-level container representing a day, project, or topic. Contains Paragraphs.

**Paragraph** (æ®µè½)  
Block-level content unit. Can be:
- Text body (æ€è€ƒã€è®°å½•)
- Heading (æ ‡é¢˜)
- AI Answer (Q&A ç»“æœ)
- Summary Card (å¤šå¡é›†æˆæ€»ç»“)
- Web Clip (å¸¦æ¥æºçš„å¼•ç”¨)

**Anchor** (é”šç‚¹)  
Inline reference to other Paragraphs/Cards, enabling bidirectional linking.

**Card** (å¡ç‰‡)  
Unified abstraction for various content types (Answer, Summary, Clip, Resonance). All cards are stored as specialized Paragraphs with `meta.card_type`.

### 2.2 Evidence & Memory System

**EventLog** (äº‹ä»¶æ—¥å¿—)  
Immutable log of all user interactions with timestamped metadata:
- `ASK_AI`, `ANSWER_RECEIVED`
- `CARD_EXPANDED`, `CARD_COLLAPSED`
- `HIGHLIGHT_ADDED`, `TAG_CHANGED`
- `SESSION_STARTED`, `SESSION_ENDED`

**Signal** (é‡ç‚¹ä¿¡å·)  
User-initiated markers indicating importance:
- `HIGHLIGHT` (â­ é‡ç‚¹)
- `QUESTION` (â“ ç–‘é—®/Open Loop)
- `ACTION_ITEM` (âœ… å¾…åŠ)
- `OBJECTION` (ğŸ§Š åå¯¹/é£é™©)
- Additional: `CONFIRM`, `BOOKMARK`, `TOPIC_SHIFT`

**Session** (ä¼šè¯)  
Continuous recording period (meeting, study session, voice memo) containing:
- Audio stream (optional, local-first)
- Real-time transcription
- User manual notes
- Timestamped Signals

**TakeawayCandidate** (å€™é€‰æ”¶è·)  
Micro-conclusion extracted from interactions:
- Auto-generated from AI Answers, Summaries, Session Key Moments
- User-manually tagged highlights
- Aggregated daily â†’ weekly â†’ monthly via compounding reviews

### 2.3 Review & Synthesis Outputs

**Daily Narrative** (æ¯æ—¥å™äº‹)  
Structured review output generated from Evidence:
1. **Narrative Summary**: Time-skeleton overview (morning/afternoon/evening)
2. **Top Takeaways**: 3-7 key learnings with evidence links
3. **Open Loops**: Unanswered questions
4. **Action Items**: Tagged tasks
5. **Resonance**: Cross-note connections (optional)

**Focus Window** (é‡ç‚¹çª—å£)  
Time range around a Signal (e.g., [t-20s, t+60s]) marked for detailed processing:
- Higher ASR transcription accuracy
- Finer-grained segmentation
- Preserved verbatim quotes for Key Moments

**Holographic Map** (å…¨æ¯ç›®å½•)  
Auto-generated filterable outline showing note structure with:
- Signal-based highlighting (â­/â“/âœ…)
- Collapsible hierarchy
- Click-to-jump navigation

---

## 3. User Experience Design

### 3.1 Core User Flows

#### Flow A: Daily Knowledge Capture (çŸ¥è¯†å·¥ä½œè€…åœºæ™¯)

**Morning: Note Creation**
1. User creates Note "2025-01-23 Project Alpha Research"
2. Types initial thoughts â†’ auto-logs `INSERT_TEXT` events
3. Asks AI "What are best practices for X?" â†’ logs `ASK_AI`
4. AI responds with detailed answer â†’ system generates:
   - Answer Card (paragraph with `card_type: ai_answer`)
   - TakeawayCandidate: "Best practice for X is Y" (auto-extracted)
5. User marks AI answer as highlight (â­) â†’ weight boost for daily review

**Afternoon: Multi-Source Integration**
1. User selects 3 existing cards (from different notes)
2. Clicks "Summarize Together" â†’ logs `MULTI_SELECT_SUMMARIZE`
3. System generates Summary Card with:
   - Integrated synthesis
   - 3-5 TakeawayCandidates (one per key point)
   - `evidence_refs` to all source card IDs

**Evening: Automatic Daily Review**
1. System triggers Daily Narrative generation (9 PM or manual)
2. Reads Evidence:
   - Timeline: sessions, Signal timestamps
   - Interactions: Ask AI, card toggles, highlights
   - Outcomes: Answer cards, Summary cards
3. Outputs Daily Narrative with:
   - "Today you focused on Project Alpha (3h), had 2 key AI discussions"
   - Top 5 Takeaways (clickable to source cards)
   - 2 Open Loops (unanswered questions)
4. User reviews in <3 min, marks satisfactory â†’ archives to knowledge base

#### Flow B: Meeting with Smart Evidence Capture (ä¼šè®®åœºæ™¯)

**Pre-Meeting**
1. User clicks "Start Meeting Session" in calendar event
2. System requests permissions:
   - Screen capture (for intelligent frame snapshots, not full video)
   - Microphone (audio saved **locally only**)
3. Starts monitoring:
   - Screen content changes â†’ auto-snapshot when page/slide changes
   - Audio recording â†’ local file with timestamp alignment

**During Meeting**
1. **Slide appears**: System detects scene change â†’ captures screenshot
2. **Slide animates**: System holds candidate slot, only saves most informative final frame
3. **User takes note**: Types "Decision: migrate to new API" â†’ auto-logs with audio offset
4. **User presses Highlight hotkey** (`Ctrl+Shift+H`): Creates `HIGHLIGHT` Signal
   - Marks current audio timestamp
   - Marks current screenshot ID
   - Opens Focus Window [t-20s, t+60s] for detailed transcription
5. **Voice cue detected**: User says "é‡ç‚¹" â†’ same as hotkey

**Post-Meeting**
1. System runs OCR on saved screenshots (throttled, on-demand)
2. Generates Meeting Bullet Notes:
   ```
   - Decision: migrate to new API [ref: image 20250123143012]
   - Risk: backward compatibility concerns [ref: image 20250123143145]
   - Action: @John to prepare migration checklist [ref: image 20250123143230]
   ```
3. User clicks `[ref: image ...]` â†’ opens screenshot + seeks audio to that timestamp
4. Bullet notes auto-added as TakeawayCandidates for daily aggregation

#### Flow C: Voice Memo with RECNote Sync (è¯­éŸ³è®°å½•åœºæ™¯)

**Scenario**: Walking and recording thoughts

1. User opens Note, starts recording via RECNote
2. Speaks continuously while occasionally typing keywords
3. Each typed paragraph gets `audioAnchor` in metadata:
   ```typescript
   meta: {
     audioAnchor: {
       recordingId: "rec_20250123_1430",
       offsetMs: 125000  // 2min 5sec into recording
     }
   }
   ```
4. Later review: clicks paragraph â†’ audio player seeks to `offsetMs` and plays
5. Audio stored locally as **16kHz mono Opus @ 24kbps** â†’ ~12MB/hour
6. Desktop app auto-runs local Whisper during idle time â†’ generates FTS index
7. User searches "prototype feedback" â†’ finds audio segment + linked paragraph

### 3.2 UI Component Specifications

#### 3.2.1 Holographic Map (å…¨æ¯ç›®å½•)

**Location**: Right sidebar (collapsible)

**Visual Design**
```
ğŸ“„ Daily Research Log 2025-01-23

â”œâ”€ ğŸ”¹ Morning Review
â”‚   â”œâ”€ â­ Key insight on API design
â”‚   â””â”€ â“ How to handle edge cases?
â”œâ”€ ğŸ”¹ Meeting Notes
â”‚   â”œâ”€ Decision: use GraphQL
â”‚   â”œâ”€ âœ… @Alice: draft schema by Friday
â”‚   â””â”€ ğŸ§Š Concern: team onboarding cost
â””â”€ ğŸ”¹ Evening Summary
    â””â”€ 3 takeaways collected
```

**Interaction**
- Click any line â†’ scroll to paragraph + highlight briefly
- Filter buttons: [â­ Highlights] [â“ Questions] [âœ… Actions] [All]
- Auto-updates on edit (debounced 500ms)
- Collapse/expand sections

#### 3.2.2 Daily Narrative Panel (æ¯æ—¥å›é¡¾é¢æ¿)

**Trigger**: Manual invoke or scheduled (9 PM daily)

**Layout**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Daily Narrative â€” 2025-01-23                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚ ğŸ“– NARRATIVE SUMMARY                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ Morning: Focused on Project Alpha research      â”‚
â”‚ (2.5h). Had productive AI discussion on API     â”‚
â”‚ architecture patterns.                           â”‚
â”‚                                                  â”‚
â”‚ Afternoon: Team meeting (1h), finalized Q1      â”‚
â”‚ roadmap. Light code review session.              â”‚
â”‚                                                  â”‚
â”‚ ğŸ¯ TOP TAKEAWAYS (5)                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ 1. REST vs GraphQL trade-offs in our context   â”‚
â”‚    [ğŸ“ See: AI Answer Card #abc123]             â”‚
â”‚                                                  â”‚
â”‚ 2. Team consensus: prioritize user auth feature â”‚
â”‚    [ğŸ“ See: Meeting Summary #def456]             â”‚
â”‚ ...                                              â”‚
â”‚                                                  â”‚
â”‚ â“ OPEN LOOPS (2)                               â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ How to migrate existing REST clients?         â”‚
â”‚ â€¢ Performance benchmarks needed for GraphQL     â”‚
â”‚                                                  â”‚
â”‚ âœ… ACTION ITEMS (3)                             â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ @Me: Draft API migration plan by Thu          â”‚
â”‚ â€¢ @Alice: Set up dev environment for GraphQL    â”‚
â”‚ â€¢ @Team: Review security checklist              â”‚
â”‚                                                  â”‚
â”‚ ğŸ”— RESONANCE (Optional)                         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ Related to: "API Design Principles" note (3mo)  â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Archive & Mark Complete]  [Regenerate]  [Export]
```

**Interaction**
- All `[ğŸ“ See: ...]` links open source card in context
- Action Items can be one-click exported to task manager (future)
- Regenerate uses updated weights/filters if user edited source notes

#### 3.2.3 Focus Window Indicator (Granola-style)

**During Session Recording**
```
ğŸ™ï¸ Recording: 00:12:34

Timeline:
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘
 â†‘                    â†‘
Key Moment 1      Key Moment 2
(user highlighted)
```

**Post-Session Summary Template**
```
Meeting Summary: Q1 Planning
Duration: 45 min | 3 Key Moments | 8 Screenshots

ğŸ“Œ KEY MOMENTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. [00:03:12 - 00:04:30] Decision: GraphQL adoption
   "We agreed the flexibility outweighs learning curve"
   [ğŸ–¼ï¸ Screenshot] [ğŸ”Š Audio]

2. [00:15:44 - 00:17:10] Risk: Team capacity concerns
   "Alice raised valid point about current sprint load"
   [ğŸ–¼ï¸ Screenshot] [ğŸ”Š Audio]

ğŸ“ SUPPORTING NOTES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Brief introductions and team updates (00:00-00:03)
- Administrative logistics discussion (00:25-00:30)
```

---

## 4. Detailed Functional Requirements

### 4.1 Evidence Collection System

**FR-Evidence-1: EventLog Capture**  
System MUST log all user interactions with immutable, timestamped events:
- Required fields: `event_id`, `user_id`, `timestamp`, `event_type`, `metadata`
- Minimum captured events: `ASK_AI`, `ANSWER_RECEIVED`, `CARD_EXPANDED`, `HIGHLIGHT_ADDED`, `TAG_CHANGED`, `SESSION_STARTED`, `SESSION_ENDED`
- Log storage: append-only, indexed by `timestamp` and `event_type`

**FR-Evidence-2: Signal Recording**  
System MUST support user-initiated Signals with:
- Hotkey support (global shortcuts, customizable)
- Voice cue detection (keyword-triggered: "é‡ç‚¹", "é—®é¢˜", "å¾…åŠ")
- UI button access (recording panel)
- Storage: linked to `note_id`, `paragraph_id`, `audio_offset_ms`, `image_id` (if applicable)

**FR-Evidence-3: Timeline Evidence**  
System SHOULD integrate calendar events (optional) and session time ranges as evidence inputs.

### 4.2 Intelligent Transcription & Snapshots

**FR-Audio-1: RECNote Integration**  
System MUST implement audio-note sync via RECNote spec:
- Audio format: **16kHz mono Opus @ 24kbps** (target <12MB/hour)
- Anchor storage: `audioAnchor { recordingId, offsetMs }` in paragraph metadata
- Playback: click paragraph â†’ audio seeks to `offsetMs` and plays
- Local processing: idle-time Whisper transcription â†’ FTS5 index
- Privacy: audio files stored locally by default, cloud sync opt-in

**FR-Audio-2: Focus Window Processing**  
For audio segments within Focus Windows (Signal Â± time delta):
- Higher transcription quality (preserve verbatim)
- Finer segmentation (sentence-level)
- Outside focus windows: aggressive compression (1-2 sentence summaries)

**FR-Snapshot-1: Intelligent Frame Capture**  
During screen recording sessions, system MUST:
- Detect scene changes (threshold: >5% pixel difference for minor change, >20% for scene boundary)
- Implement candidate slot mechanism: only save most informative frame per scene
- NOT save full video files (only discrete screenshots)
- Generate screenshots with metadata: `image_id`, `scene_id`, `created_at_ms`, `hash_32x32`, `similarity_to_prev`

**FR-Snapshot-2: OCR Integration**  
System SHOULD run OCR on saved screenshots:
- Execution: throttled/on-demand to avoid blocking UI
- Output: `ocr_text` + `ocr_confidence` stored with image
- Usage: searchable, included in meeting note generation

**FR-Snapshot-3: Evidence Linking**  
Each Highlight/Signal MUST record `image_id` of current/nearest screenshot for clickable references in generated notes.

### 4.3 Takeaway Settlement Layer

**FR-Takeaway-1: Automatic Candidate Generation**  
System MUST auto-generate TakeawayCandidates on:
- `AI_ANSWERED`: 1 candidate from answer summary
- `SUMMARY_GENERATED`: 3-5 candidates from key points
- `SESSION_ENDED`: N candidates from Key Moments (focus windows)

**FR-Takeaway-2: Manual Tagging**  
User MUST be able to manually mark any paragraph/card as Takeaway:
- UI: star/bookmark icon or context menu
- Creates `source_type: manual` candidate with highest weight

**FR-Takeaway-3: Candidate Schema**  
TakeawayCandidate storage MUST include:
```typescript
{
  takeaway_id: string;
  user_id: string;
  date: string; // YYYY-MM-DD
  source_type: 'card' | 'session' | 'web_clip' | 'manual';
  source_id: string;
  created_at: timestamp;
  text: string; // â‰¤200 chars
  topic?: string;
  embedding?: Float32Array; // optional, for clustering
  weight: number;
  evidence_refs: Array<{type: string, id: string}>;
  status: 'active' | 'archived' | 'rejected';
}
```

**FR-Takeaway-4: Weight Calculation**  
Weight formula: `manual_signal + system_signal + behavior_signal + recency_signal`

| Signal Type | Weight Component | MVP Inclusion |
|-------------|------------------|---------------|
| Manual HIGHLIGHT | +10 | âœ… Yes |
| Manual ACTION_ITEM | +15 | âœ… Yes |
| Manual QUESTION | +12 | âœ… Yes |
| From Focus Window Key Moment | +8 | âœ… Yes |
| From Multi-Card Summary | +6 | âœ… Yes |
| Card expand count | +1 per expand (max +5) | âš ï¸ Optional |
| Reference count | +2 per reference | âš ï¸ Optional |
| Recency boost | +3 if within last 2h | âŒ Post-MVP |

### 4.4 Daily/Weekly/Monthly Review Generation

**FR-Review-1: Daily Narrative Generation**  
System MUST support on-demand or scheduled Daily Narrative generation with:
- Input: all Evidence from target date (Timeline, Interactions, Outcomes)
- Output sections:
  1. **Narrative Summary**: 2-4 paragraphs, time-segmented (morning/afternoon/evening or session-based)
  2. **Top Takeaways**: 3-7 items ranked by weight, each with clickable `evidence_refs`
  3. **Open Loops**: extracted Questions + AI-detected unresolved items
  4. **Action Items**: extracted from `ACTION_ITEM` Signals + summary parsing
  5. **Resonance** (optional): cross-note connections via embedding similarity

**FR-Review-2: Weekly/Monthly Synthesis**  
System SHOULD support compounding reviews:
- Weekly: aggregate Daily Narratives from past 7 days â†’ meta-synthesis
- Monthly: aggregate Weekly summaries â†’ thematic trends
- All reviews maintain backward `evidence_refs` to atomic sources

**FR-Review-3: Regeneration Support**  
User MUST be able to regenerate any review after:
- Editing source notes
- Changing Signal tags
- Adjusting filters (e.g., exclude certain topics)

### 4.5 Holographic Map (Filterable Outline)

**FR-Map-1: Auto-Generation**  
System MUST auto-generate outline from note structure:
- Hierarchy: H1/H2/H3 â†’ nested list
- Signal decoration: prefix lines with â­/â“/âœ… icons based on paragraph Signals
- Update trigger: debounced on any note edit (500ms delay)

**FR-Map-2: Filtering**  
User MUST be able to filter outline by Signal type:
- Buttons: [â­ Highlights] [â“ Questions] [âœ… Actions] [All]
- Filtered view hides non-matching items, shows ancestors for context

**FR-Map-3: Navigation**  
Click any outline item â†’ scroll to paragraph + brief highlight animation (500ms)

### 4.6 Resonance (Cross-Note Connections)

**FR-Resonance-1: Query Mechanism**  
System MUST support Resonance queries:
- Input: selected text/paragraph embedding
- Search: vector similarity across all notes (excluding current)
- Threshold: configurable similarity score (default 0.75)
- Output: ranked list of related paragraphs with preview snippets

**FR-Resonance-2: Resonance Cards**  
User can save Resonance results as Cards:
- Card type: `resonance`
- Stores: query source + matched results + similarity scores
- Bidirectional links: both source and target paragraphs gain backlinks

**FR-Resonance-3: Review Integration**  
Daily/Weekly Narratives SHOULD include Resonance section showing:
- "Today's ideas relate to [Note X from 3 months ago]"
- Auto-detected via highest similarity match above threshold

---

## 5. Technical Architecture

### 5.1 Data Models

#### EventLog Schema (Immutable)
```sql
CREATE TABLE event_log (
  event_id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  timestamp INTEGER NOT NULL,  -- Unix ms
  event_type TEXT NOT NULL,    -- 'ASK_AI', 'HIGHLIGHT_ADDED', etc.
  note_id TEXT,
  paragraph_id TEXT,
  session_id TEXT,
  metadata JSON,               -- flexible event-specific data
  
  INDEX idx_timestamp (timestamp),
  INDEX idx_event_type (event_type),
  INDEX idx_user_date (user_id, date(timestamp/1000, 'unixepoch'))
);
```

#### Signals Schema
```sql
CREATE TABLE signals (
  signal_id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  note_id TEXT NOT NULL,
  paragraph_id TEXT,
  signal_type TEXT NOT NULL,   -- 'HIGHLIGHT', 'QUESTION', 'ACTION_ITEM'
  created_at INTEGER NOT NULL,
  audio_offset_ms INTEGER,
  image_id TEXT,
  metadata JSON,
  
  FOREIGN KEY (note_id) REFERENCES notes(id),
  INDEX idx_note_signals (note_id),
  INDEX idx_signal_type (signal_type)
);
```

#### TakeawayCandidate Schema
```sql
CREATE TABLE takeaway_candidates (
  takeaway_id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  date TEXT NOT NULL,          -- YYYY-MM-DD
  source_type TEXT NOT NULL,   -- 'card', 'session', 'manual'
  source_id TEXT NOT NULL,
  created_at INTEGER NOT NULL,
  text TEXT NOT NULL,          -- max 200 chars
  topic TEXT,
  embedding BLOB,              -- Float32Array serialized
  weight REAL NOT NULL,
  evidence_refs JSON NOT NULL, -- [{type, id}, ...]
  status TEXT DEFAULT 'active',
  
  INDEX idx_user_date (user_id, date),
  INDEX idx_weight (weight DESC)
);
```

#### Session Schema (Audio/Meeting)
```sql
CREATE TABLE sessions (
  session_id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL,
  note_id TEXT,
  session_type TEXT,           -- 'meeting', 'voice_memo', 'study'
  started_at INTEGER NOT NULL,
  ended_at INTEGER,
  duration_ms INTEGER,
  audio_file_path TEXT,        -- local file system path
  audio_remote_url TEXT,       -- R2/S3 URL (optional)
  metadata JSON,
  
  INDEX idx_user_sessions (user_id, started_at)
);
```

#### Image (Snapshot) Schema
```sql
CREATE TABLE images (
  image_id TEXT PRIMARY KEY,   -- timestamp-based: YYYYMMDDHHmmssSSS
  session_id TEXT NOT NULL,
  created_at_ms INTEGER NOT NULL,
  scene_id TEXT NOT NULL,
  hash_32x32 TEXT,
  similarity_to_prev REAL,
  sharpness REAL,
  density REAL,
  blob_uri TEXT NOT NULL,      -- IndexedDB or File System ref
  thumb_uri TEXT,
  ocr_text TEXT,
  ocr_confidence REAL,
  
  FOREIGN KEY (session_id) REFERENCES sessions(session_id),
  INDEX idx_session_images (session_id, created_at_ms)
);
```

### 5.2 Weight Calculation Implementation

```typescript
interface WeightConfig {
  manualHighlight: number;    // 10
  manualQuestion: number;     // 12
  manualAction: number;       // 15
  focusWindowMoment: number;  // 8
  multiCardSummary: number;   // 6
  cardExpand: number;         // 1 per expand, max 5
  referenceCount: number;     // 2 per ref
  recencyBoost: number;       // 3 if <2h old
}

function calculateTakeawayWeight(
  candidate: TakeawayCandidate,
  config: WeightConfig,
  behaviorData?: {
    expandCount: number;
    refCount: number;
    ageMs: number;
  }
): number {
  let weight = 0;
  
  // Manual signals (highest priority)
  const signalType = candidate.metadata?.signalType;
  if (signalType === 'HIGHLIGHT') weight += config.manualHighlight;
  if (signalType === 'QUESTION') weight += config.manualQuestion;
  if (signalType === 'ACTION_ITEM') weight += config.manualAction;
  
  // System signals
  if (candidate.source_type === 'session' && candidate.metadata?.isFocusWindow) {
    weight += config.focusWindowMoment;
  }
  if (candidate.source_type === 'card' && candidate.metadata?.isMultiCardSummary) {
    weight += config.multiCardSummary;
  }
  
  // Behavior signals (optional)
  if (behaviorData) {
    weight += Math.min(behaviorData.expandCount * config.cardExpand, 5);
    weight += behaviorData.refCount * config.referenceCount;
    if (behaviorData.ageMs < 2 * 60 * 60 * 1000) { // <2h
      weight += config.recencyBoost;
    }
  }
  
  return weight;
}
```

### 5.3 Focus Window Detection

```typescript
interface Signal {
  timestamp: number; // Unix ms
  type: 'HIGHLIGHT' | 'QUESTION' | 'ACTION_ITEM';
}

interface FocusWindow {
  startMs: number;
  endMs: number;
  signals: Signal[];
}

function detectFocusWindows(
  signals: Signal[],
  config: {
    preBuffer: number;  // 20000 (20s)
    postBuffer: number; // 60000 (60s)
    mergeThreshold: number; // 30000 (30s)
    maxWindowDuration: number; // 300000 (5min)
  }
): FocusWindow[] {
  const windows: FocusWindow[] = [];
  
  signals
    .filter(s => s.type === 'HIGHLIGHT') // Focus primarily on highlights
    .sort((a, b) => a.timestamp - b.timestamp)
    .forEach((signal, idx) => {
      const start = signal.timestamp - config.preBuffer;
      const end = signal.timestamp + config.postBuffer;
      
      // Try merge with last window
      const lastWindow = windows[windows.length - 1];
      if (lastWindow && start - lastWindow.endMs < config.mergeThreshold) {
        // Merge and extend
        lastWindow.endMs = Math.min(end, lastWindow.startMs + config.maxWindowDuration);
        lastWindow.signals.push(signal);
      } else {
        // Create new window
        windows.push({
          startMs: start,
          endMs: Math.min(end, start + config.maxWindowDuration),
          signals: [signal]
        });
      }
    });
  
  return windows;
}
```

### 5.4 Intelligent Snapshot Algorithm

```typescript
interface FrameMetadata {
  timestamp: number;
  hash: string;      // 32x32 perceptual hash
  sharpness: number; // Laplacian variance
  density: number;   // Edge count / entropy
}

class SnapshotManager {
  private candidateSlot: FrameMetadata | null = null;
  private lastSavedHash: string | null = null;
  
  processFrame(frame: ImageData, timestamp: number): boolean {
    const meta = this.analyzeFrame(frame, timestamp);
    
    // Detect scene change
    const diffRatio = this.lastSavedHash 
      ? this.hammingDistance(meta.hash, this.lastSavedHash) / 1024
      : 1.0;
    
    if (diffRatio > 0.20) {
      // Major scene change â†’ save candidate and start new slot
      this.saveCandidate();
      this.candidateSlot = meta;
      return true;
    } else if (diffRatio > 0.05) {
      // Minor change â†’ update candidate if more informative
      if (!this.candidateSlot || this.isMoreInformative(meta, this.candidateSlot)) {
        this.candidateSlot = meta;
      }
      return false;
    }
    
    return false; // No significant change
  }
  
  private isMoreInformative(newFrame: FrameMetadata, oldFrame: FrameMetadata): boolean {
    // Weighted scoring: prefer sharper + denser frames
    const newScore = newFrame.sharpness * 0.6 + newFrame.density * 0.4;
    const oldScore = oldFrame.sharpness * 0.6 + oldFrame.density * 0.4;
    return newScore > oldScore * 1.1; // 10% threshold to avoid jitter
  }
  
  private analyzeFrame(frame: ImageData, timestamp: number): FrameMetadata {
    // Implementation: compute perceptual hash, Laplacian variance, edge density
    // Placeholder return
    return {
      timestamp,
      hash: 'computed_hash',
      sharpness: 120.5,
      density: 0.34
    };
  }
  
  private saveCandidate(): void {
    if (this.candidateSlot) {
      // Persist to IndexedDB/File System
      this.lastSavedHash = this.candidateSlot.hash;
      // ... storage logic
      this.candidateSlot = null;
    }
  }
  
  private hammingDistance(hash1: string, hash2: string): number {
    // Count differing bits
    let distance = 0;
    for (let i = 0; i < hash1.length; i++) {
      if (hash1[i] !== hash2[i]) distance++;
    }
    return distance;
  }
}
```

---

## 6. External Integrations & Dependencies

### 6.1 RECNote Audio Module

**Purpose**: Provide audio-note timestamp sync for click-to-play navigation

**Integration Points**
1. **Recording API**:
   ```typescript
   interface RECNoteRecorder {
     startRecording(noteId: string): Promise<{ recordingId: string }>;
     stopRecording(): Promise<{ duration: number; filePath: string }>;
     getCurrentOffset(): number; // milliseconds since start
   }
   ```

2. **Playback API**:
   ```typescript
   interface RECNotePlayer {
     loadRecording(recordingId: string): Promise<void>;
     seekTo(offsetMs: number): void;
     play(): void;
     pause(): void;
   }
   ```

3. **Anchor Storage**: Paragraphs with audio anchors store:
   ```typescript
   meta: {
     audioAnchor: {
       recordingId: string;
       offsetMs: number;
     }
   }
   ```

**Technical Specs** (from RECNote PRD)
- Audio format: **16kHz mono Opus @ 24kbps** â†’ ~12MB/hour
- Local processing: Whisper transcription during idle CPU time
- FTS indexing: `FTS5` + `sqlite-vss` for semantic search
- Privacy: Local-first storage, cloud sync opt-in

**Responsibilities**
- RECNote handles: recording, encoding, playback, transcription
- Eventlog handles: anchor metadata, UI triggers, review integration

### 6.2 Intelligent Snapshot Module

**Purpose**: Capture meeting/screen evidence without full video recording

**Integration Points**
1. **Session Lifecycle**:
   ```typescript
   interface SnapshotSession {
     startCapture(config: CaptureConfig): Promise<{ sessionId: string }>;
     stopCapture(): Promise<{ imageCount: number; totalSize: number }>;
     onFrameCaptured: (imageId: string, timestamp: number) => void;
   }
   ```

2. **Image Retrieval**:
   ```typescript
   interface SnapshotAPI {
     getImage(imageId: string): Promise<{ blob: Blob; ocr?: string }>;
     getSessionImages(sessionId: string): Promise<ImageRecord[]>;
     runOCR(imageId: string): Promise<{ text: string; confidence: number }>;
   }
   ```

3. **Highlight Binding**: When user creates `HIGHLIGHT` Signal during session:
   ```typescript
   // EventLog creates Signal with current context
   const signal = {
     signal_id: uuid(),
     signal_type: 'HIGHLIGHT',
     created_at: Date.now(),
     image_id: await snapshotAPI.getCurrentImageId(), // latest or force capture
     audio_offset_ms: recnoteRecorder.getCurrentOffset()
   };
   ```

**Technical Specs** (from Snapshot PRD)
- Scene detection: >20% change â†’ new scene, >5% â†’ candidate update
- Candidate slot: only save most informative frame per scene
- Quality metrics: sharpness (Laplacian variance) + density (edge count)
- Storage: IndexedDB (web) or File System (Electron), compressed WebP/JPEG

**Responsibilities**
- Snapshot module handles: frame capture, scene detection, OCR execution
- Eventlog handles: Signal-to-image binding, reference rendering in reviews

---

## 7. Implementation Roadmap

### MVP-1: Evidence Foundation (Weeks 1-3)

**Goal**: Establish reliable evidence capture without review generation

**Deliverables**
- [ ] EventLog table + logging infrastructure for core events (`ASK_AI`, `CARD_EXPANDED`, `HIGHLIGHT_ADDED`)
- [ ] Signals table + UI for manual tagging (â­/â“/âœ… buttons)
- [ ] Holographic Map auto-generation with Signal decoration
- [ ] Basic filtering (by Signal type)

**Success Criteria**
- All user interactions logged with <50ms latency
- Holographic Map updates within 500ms of note edits
- Manual Signals persist correctly and display in outline

### MVP-2: Takeaway Settlement (Weeks 4-6)

**Goal**: Auto-generate TakeawayCandidates from interactions

**Deliverables**
- [ ] TakeawayCandidate schema + storage
- [ ] Auto-generation logic:
  - AI Answer â†’ 1 takeaway
  - Multi-card Summary â†’ 3-5 takeaways
- [ ] Manual tagging UI (star icon on paragraphs)
- [ ] Weight calculation (manual + system signals only)

**Success Criteria**
- Takeaways auto-created on all qualifying events
- Manual tagging adds highest-weight candidates
- Can query top N takeaways for a given date

### MVP-3: Daily Narrative (Weeks 7-10)

**Goal**: First end-to-end review generation

**Deliverables**
- [ ] Daily Narrative generation service
- [ ] UI panel for viewing/regenerating narratives
- [ ] Evidence linking (clickable `[ğŸ“ See: ...]` refs)
- [ ] Sections: Narrative Summary, Top Takeaways, Open Loops, Action Items

**Success Criteria**
- Generate coherent 1-page summary from day's evidence
- All takeaways clickable to source cards
- User can regenerate after editing notes
- <30s generation time for typical day (50-100 events)

### MVP-4: Audio Sync (Weeks 11-13)

**Goal**: Integrate RECNote for audio-note anchoring

**Deliverables**
- [ ] RECNote recording integration (start/stop in note UI)
- [ ] `audioAnchor` metadata storage in paragraphs
- [ ] Click-to-play: paragraph â†’ audio seeks to offset
- [ ] Local Whisper transcription (background task)

**Success Criteria**
- Audio recorded at <12MB/hour (Opus 24kbps)
- Accurate offset capture (Â±1s)
- Smooth playback seeking
- Transcription completes within 2x real-time on idle CPU

### MVP-5: Meeting Snapshots (Weeks 14-17)

**Goal**: Intelligent frame capture for meeting evidence

**Deliverables**
- [ ] Screen capture session management
- [ ] Scene detection + candidate slot algorithm
- [ ] Signal-to-image binding (Highlight â†’ current screenshot)
- [ ] OCR processing (throttled)
- [ ] Meeting bullet notes generation with `[ref: image ...]`

**Success Criteria**
- 1-hour meeting â†’ 30-80 screenshots (not thousands)
- Key moments linked to correct images
- OCR text searchable
- User can click ref â†’ view image + play audio at timestamp

### Post-MVP: Advanced Features

**Phase 2 (Months 6-9)**
- [ ] Weekly/Monthly compounding reviews
- [ ] Resonance query + card generation
- [ ] Voice cue detection for hands-free Signal creation
- [ ] Behavior-based weight components (expand count, ref count)
- [ ] Mobile app with cloud processing for Pro users

**Phase 3 (Months 10-12)**
- [ ] Calendar integration (import events as Timeline Evidence)
- [ ] Task manager export (Action Items â†’ Todoist/etc.)
- [ ] Collaborative session sharing (privacy-controlled)
- [ ] Advanced analytics (topic trends, productivity insights)

---

## 8. Success Metrics

### User Engagement
- **Daily Active Users with Review**: % of users generating â‰¥1 Daily Narrative per week
- **Average Review Time**: Target <3 min to read daily narrative
- **Takeaway Retention**: % of takeaways marked as valuable (upvoted/archived vs. deleted)

### Technical Performance
- **EventLog Write Latency**: p95 <50ms
- **Daily Narrative Generation Time**: p95 <30s for typical day
- **Audio Processing**: Whisper transcription completes within 2x real-time
- **Snapshot Efficiency**: Meeting sessions generate <10% frame count vs. 1fps full recording

### Quality Indicators
- **Takeaway Relevance**: User feedback score (1-5 scale) avg >3.5
- **Signal Precision**: % of manually tagged Highlights appearing in Top Takeaways >80%
- **OCR Accuracy**: Avg confidence score >70% on saved screenshots

---

## 9. Privacy & Security Considerations

### Data Residency
- **Local-First by Default**: Audio files and screenshots stored on-device
- **Cloud Sync Opt-In**: User explicitly enables cloud backup, with clear data policy disclosure
- **Encryption**: All cloud-synced media encrypted at rest (AES-256)

### User Control
- **Granular Deletion**: User can delete individual events, sessions, images
- **Session Privacy Mode**: Option to record "off the record" (no cloud sync, auto-delete after N days)
- **Evidence Redaction**: Ability to blur/delete specific screenshots retroactively

### Compliance
- **GDPR**: Right to access, export, delete all personal data
- **Data Export**: Full evidence archive exportable as JSON + media files
- **Transparency**: Clear disclosure in UI when recording audio/screen

---

## 10. Open Questions & Future Explorations

### Technical Debt Items
- **Embedding Model Selection**: Which model for takeaway clustering? (sentence-transformers vs. OpenAI)
- **OCR Library**: Tesseract.js (local) vs. cloud OCR (Google Vision)? Latency vs. cost trade-off
- **Mobile Audio Processing**: Can we run lightweight Whisper on-device, or always defer to desktop?

### Design Ambiguities
- **Resonance Threshold Tuning**: What similarity score works best? User-adjustable or auto-calibrated?
- **Focus Window Merging**: How to handle 3+ highlights in rapid succession? Current logic may over-merge
- **Takeaway Deduplication**: How to detect near-duplicate takeaways across days? Embedding similarity + text fuzzy match?

### Product Strategy
- **Monetization**: Free tier (local-only) vs. Pro (cloud + instant processing)? Storage limits?
- **Collaboration**: Should sessions be shareable? Privacy implications for meeting recordings
- **Third-Party Integrations**: Which calendar/task managers to prioritize? API design?

---

## 11. Appendix: Key Terminology Quick Reference

| Term | Definition | Storage |
|------|------------|---------|
| **EventLog** | Immutable interaction log | `event_log` table |
| **Signal** | User-initiated importance marker | `signals` table |
| **Session** | Continuous recording period | `sessions` table |
| **TakeawayCandidate** | Micro-conclusion for daily aggregation | `takeaway_candidates` table |
| **Focus Window** | High-priority time range around Signal | Computed on-demand |
| **Holographic Map** | Auto-generated filterable outline | Generated from note structure |
| **Daily Narrative** | Structured daily review output | Generated document, optionally saved |
| **Resonance** | Cross-note semantic connections | `resonance_queries` + card type |
| **RECNote** | Audio-note timestamp sync module | Separate module, integrated via API |
| **Intelligent Snapshot** | Smart meeting screenshot capture | Separate module, integrated via API |

---

**Document Status**: Ready for implementation. All core requirements specified with sufficient detail for development. Open questions flagged for resolution during sprint planning.

**Next Steps**: 
1. Technical review with engineering team
2. Finalize MVP-1 sprint backlog
3. Set up EventLog infrastructure and testing framework
4. Begin Holographic Map UI implementation
